{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41834d64-50c6-460c-8861-dc6e960a8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd649b0b-a843-40b1-9aa7-a789f87cb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus d'articles (chaque article est une liste de mots)\n",
    "articles = [\n",
    "    [\"machine\", \"learning\", \"intelligence\", \"artificielle\"],\n",
    "    [\"réseaux\", \"neurones\", \"profonds\", \"deep\", \"learning\"],\n",
    "    [\"traitement\", \"langage\", \"naturel\", \"NLP\"],\n",
    "    [\"voitures\", \"autonomes\", \"apprentissage\", \"automatique\"],\n",
    "    [\"vision\", \"ordinateur\", \"reconnaissance\", \"images\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de83580a-a760-48d1-8acd-ed4f32d24b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle Word2Vec\n",
    "model_w2v = Word2Vec(articles, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047cbe60-375f-4fe5-8208-be9d337dfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer la moyenne des vecteurs d'un article\n",
    "def get_embedding(article):\n",
    "    vectors = [model_w2v.wv[word] for word in article if word in model_w2v.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "# Stocker les embeddings des articles\n",
    "article_embeddings = np.array([get_embedding(article) for article in articles])\n",
    "\n",
    "# Fonction de recommandation\n",
    "def recommend(article_index, top_n=3):\n",
    "    similarities = cosine_similarity([article_embeddings[article_index]], article_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][1:top_n+1]  # Ignorer l'article de base\n",
    "\n",
    "    print(f\"\\nArticles similaires à : {' '.join(articles[article_index])}\")\n",
    "    for idx in top_indices:\n",
    "        print(f\"- {' '.join(articles[idx])} (Score : {similarities[idx]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f168a5f6-d597-4a4a-b85d-dd95f8e4d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Articles similaires à : traitement langage naturel NLP\n",
      "- machine learning intelligence artificielle (Score : 0.10)\n",
      "- voitures autonomes apprentissage automatique (Score : -0.06)\n",
      "- réseaux neurones profonds deep learning (Score : -0.06)\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation : Recommander des articles similaires à l'article sur \"NLP\"\n",
    "recommend(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c5701-7ddf-468f-a33f-5e8ba55a7a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
